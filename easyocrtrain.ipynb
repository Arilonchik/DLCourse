{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/JaidedAI/EasyOCR"
      ],
      "metadata": {
        "id": "M5DNrSp2LLne",
        "outputId": "67c1784c-acd1-4a8f-9ff1-d8b530392f6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EasyOCR'...\n",
            "remote: Enumerating objects: 2487, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 2487 (delta 8), reused 37 (delta 7), pack-reused 2441\n",
            "Receiving objects: 100% (2487/2487), 148.72 MiB | 13.02 MiB/s, done.\n",
            "Resolving deltas: 100% (1473/1473), done.\n",
            "Checking out files: 100% (301/301), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/en.zip"
      ],
      "metadata": {
        "id": "i5AfpQZfLLlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "13VaAXBTMQ1C",
        "outputId": "e481c417-f4a9-4317-d500-91d00ae001ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/EasyOCR/trainer/all_data"
      ],
      "metadata": {
        "id": "u45d3-OzLLin",
        "outputId": "1d75eb29-37e6-479d-f072-6aaa07af56de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/EasyOCR/trainer/all_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "id": "e9_1lCBEV9m8",
        "outputId": "8dced131-f7aa-463c-9bf3-450d1fc2c151",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/EasyOCR/trainer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch.backends.cudnn as cudnn\n",
        "import yaml\n",
        "from train import train\n",
        "from utils import AttrDict\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "S7SUckbcLLgQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cudnn.benchmark = True\n",
        "cudnn.deterministic = False"
      ],
      "metadata": {
        "id": "8WJr1oqiLLdp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tes import validation"
      ],
      "metadata": {
        "id": "3lRMI-x9Pb5m"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_config(file_path):\n",
        "    with open(file_path, 'r', encoding=\"utf8\") as stream:\n",
        "        opt = yaml.safe_load(stream)\n",
        "    opt = AttrDict(opt)\n",
        "    if opt.lang_char == 'None':\n",
        "        characters = ''\n",
        "        for data in opt['select_data'].split('-'):\n",
        "            csv_path = os.path.join(opt['train_data'], data, 'labels.csv')\n",
        "            df = pd.read_csv(csv_path, sep='^([^,]+),', engine='python', usecols=['filename', 'words'], keep_default_na=False)\n",
        "            all_char = ''.join(df['words'])\n",
        "            characters += ''.join(set(all_char))\n",
        "        characters = sorted(set(characters))\n",
        "        opt.character= ''.join(characters)\n",
        "    else:\n",
        "        opt.character = opt.number + opt.symbol + opt.lang_char\n",
        "    os.makedirs(f'./saved_models/{opt.experiment_name}', exist_ok=True)\n",
        "    return opt"
      ],
      "metadata": {
        "id": "2YHyt3gCLLar"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = get_config(\"config_files/en_filtered_config.yaml\")\n",
        "train(opt, amp=False)"
      ],
      "metadata": {
        "id": "XBQMK5k6LLYI",
        "outputId": "98c8972e-4767-4cf7-83ab-c1491d4670f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering the images containing characters which are not in opt.character\n",
            "Filtering the images whose label is longer than opt.batch_max_length\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root: all_data\n",
            "opt.select_data: ['en_train_filtered']\n",
            "opt.batch_ratio: ['1']\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root:    all_data\t dataset: en_train_filtered\n",
            "all_data/en_train_filtered\n",
            "sub-directory:\t/en_train_filtered\t num samples: 1000\n",
            "num total samples of en_train_filtered: 1000 x 1.0 (total_data_usage_ratio) = 1000\n",
            "num samples of en_train_filtered per batch: 32 x 1.0 (batch_ratio) = 32\n",
            "--------------------------------------------------------------------------------\n",
            "Total_batch_size: 32 = 32\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root:    all_data/en_val\t dataset: /\n",
            "all_data/en_val/\n",
            "sub-directory:\t/.\t num samples: 2\n",
            "--------------------------------------------------------------------------------\n",
            "No Transformation module specified\n",
            "model input parameters 64 600 20 1 256 256 163 34 None VGG BiLSTM CTC\n",
            "Model:\n",
            "DataParallel(\n",
            "  (module): Model(\n",
            "    (FeatureExtraction): VGG_FeatureExtractor(\n",
            "      (ConvNet): Sequential(\n",
            "        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): ReLU(inplace=True)\n",
            "        (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (7): ReLU(inplace=True)\n",
            "        (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (9): ReLU(inplace=True)\n",
            "        (10): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
            "        (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (13): ReLU(inplace=True)\n",
            "        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (16): ReLU(inplace=True)\n",
            "        (17): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
            "        (18): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
            "        (19): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
            "    (SequenceModeling): Sequential(\n",
            "      (0): BidirectionalLSTM(\n",
            "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
            "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
            "      )\n",
            "      (1): BidirectionalLSTM(\n",
            "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
            "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (Prediction): Linear(in_features=256, out_features=163, bias=True)\n",
            "  )\n",
            ")\n",
            "Modules, Parameters\n",
            "module.FeatureExtraction.ConvNet.0.weight 288\n",
            "module.FeatureExtraction.ConvNet.0.bias 32\n",
            "module.FeatureExtraction.ConvNet.3.weight 18432\n",
            "module.FeatureExtraction.ConvNet.3.bias 64\n",
            "module.FeatureExtraction.ConvNet.6.weight 73728\n",
            "module.FeatureExtraction.ConvNet.6.bias 128\n",
            "module.FeatureExtraction.ConvNet.8.weight 147456\n",
            "module.FeatureExtraction.ConvNet.8.bias 128\n",
            "module.FeatureExtraction.ConvNet.11.weight 294912\n",
            "module.FeatureExtraction.ConvNet.12.weight 256\n",
            "module.FeatureExtraction.ConvNet.12.bias 256\n",
            "module.FeatureExtraction.ConvNet.14.weight 589824\n",
            "module.FeatureExtraction.ConvNet.15.weight 256\n",
            "module.FeatureExtraction.ConvNet.15.bias 256\n",
            "module.FeatureExtraction.ConvNet.18.weight 262144\n",
            "module.FeatureExtraction.ConvNet.18.bias 256\n",
            "module.SequenceModeling.0.rnn.weight_ih_l0 262144\n",
            "module.SequenceModeling.0.rnn.weight_hh_l0 262144\n",
            "module.SequenceModeling.0.rnn.bias_ih_l0 1024\n",
            "module.SequenceModeling.0.rnn.bias_hh_l0 1024\n",
            "module.SequenceModeling.0.rnn.weight_ih_l0_reverse 262144\n",
            "module.SequenceModeling.0.rnn.weight_hh_l0_reverse 262144\n",
            "module.SequenceModeling.0.rnn.bias_ih_l0_reverse 1024\n",
            "module.SequenceModeling.0.rnn.bias_hh_l0_reverse 1024\n",
            "module.SequenceModeling.0.linear.weight 131072\n",
            "module.SequenceModeling.0.linear.bias 256\n",
            "module.SequenceModeling.1.rnn.weight_ih_l0 262144\n",
            "module.SequenceModeling.1.rnn.weight_hh_l0 262144\n",
            "module.SequenceModeling.1.rnn.bias_ih_l0 1024\n",
            "module.SequenceModeling.1.rnn.bias_hh_l0 1024\n",
            "module.SequenceModeling.1.rnn.weight_ih_l0_reverse 262144\n",
            "module.SequenceModeling.1.rnn.weight_hh_l0_reverse 262144\n",
            "module.SequenceModeling.1.rnn.bias_ih_l0_reverse 1024\n",
            "module.SequenceModeling.1.rnn.bias_hh_l0_reverse 1024\n",
            "module.SequenceModeling.1.linear.weight 131072\n",
            "module.SequenceModeling.1.linear.bias 256\n",
            "module.Prediction.weight 41728\n",
            "module.Prediction.bias 163\n",
            "Total Trainable Params: 3798307\n",
            "Trainable params num :  3798307\n",
            "Optimizer:\n",
            "Adadelta (\n",
            "Parameter Group 0\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    lr: 1.0\n",
            "    maximize: False\n",
            "    rho: 0.95\n",
            "    weight_decay: 0\n",
            ")\n",
            "------------ Options -------------\n",
            "number: 0123456789\n",
            "symbol: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ €\n",
            "lang_char: ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzАБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдеёжзийклмнопрстуфхцчшщъыьэюя\n",
            "experiment_name: en_filtered\n",
            "train_data: all_data\n",
            "valid_data: all_data/en_val\n",
            "manualSeed: 1111\n",
            "workers: 6\n",
            "batch_size: 32\n",
            "num_iter: 10000\n",
            "valInterval: 10000\n",
            "saved_model: \n",
            "FT: False\n",
            "optim: False\n",
            "lr: 1.0\n",
            "beta1: 0.9\n",
            "rho: 0.95\n",
            "eps: 1e-08\n",
            "grad_clip: 5\n",
            "select_data: ['en_train_filtered']\n",
            "batch_ratio: ['1']\n",
            "total_data_usage_ratio: 1.0\n",
            "batch_max_length: 34\n",
            "imgH: 64\n",
            "imgW: 600\n",
            "rgb: False\n",
            "contrast_adjust: 0.0\n",
            "sensitive: True\n",
            "PAD: True\n",
            "data_filtering_off: False\n",
            "Transformation: None\n",
            "FeatureExtraction: VGG\n",
            "SequenceModeling: BiLSTM\n",
            "Prediction: CTC\n",
            "num_fiducial: 20\n",
            "input_channel: 1\n",
            "output_channel: 256\n",
            "hidden_size: 256\n",
            "decode: greedy\n",
            "new_prediction: False\n",
            "freeze_FeatureFxtraction: False\n",
            "freeze_SequenceModeling: False\n",
            "character: 0123456789!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ €ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzАБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдеёжзийклмнопрстуфхцчшщъыьэюя\n",
            "num_class: 163\n",
            "---------------------------------------\n",
            "\n",
            "training time:  1331.489269733429\n",
            "[10000/10000] Train loss: 0.28940, Valid loss: 13.65331, Elapsed_time: 1331.49079\n",
            "Current_accuracy : 0.000, Current_norm_ED  : 0.1806\n",
            "Best_accuracy    : 0.000, Best_norm_ED     : 0.1806\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "М020УВ77                  | H00190                    | 0.7033\tFalse\n",
            "С411ВТ177                 | H0150                     | 0.4826\tFalse\n",
            "--------------------------------------------------------------------------------\n",
            "validation time:  0.50174880027771\n",
            "end the training\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Добро пожаловать в Colaboratory!",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}