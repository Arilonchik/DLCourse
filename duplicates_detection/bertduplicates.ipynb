{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom transformers import BertTokenizerFast, BertForSequenceClassification, get_linear_schedule_with_warmup, AdamW\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom tqdm import tqdm \nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\nimport os\nimport numpy as np\nimport random\nfrom sklearn.metrics import accuracy_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-13T14:38:44.348191Z","iopub.execute_input":"2022-10-13T14:38:44.348593Z","iopub.status.idle":"2022-10-13T14:38:51.611806Z","shell.execute_reply.started":"2022-10-13T14:38:44.348510Z","shell.execute_reply":"2022-10-13T14:38:51.610673Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/TrainDuplicates/traincleaned.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-10-13T14:38:54.108807Z","iopub.execute_input":"2022-10-13T14:38:54.109439Z","iopub.status.idle":"2022-10-13T14:38:54.139198Z","shell.execute_reply.started":"2022-10-13T14:38:54.109397Z","shell.execute_reply":"2022-10-13T14:38:54.138283Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df.sample(15)","metadata":{"execution":{"iopub.status.busy":"2022-10-13T14:38:58.644668Z","iopub.execute_input":"2022-10-13T14:38:58.645060Z","iopub.status.idle":"2022-10-13T14:38:58.674739Z","shell.execute_reply.started":"2022-10-13T14:38:58.645026Z","shell.execute_reply":"2022-10-13T14:38:58.672990Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"      Unnamed: 0                                             name_1  \\\n4798        5488                                       ООО Руспласт   \n1264         688                                   Dawn Imp. & Exp.   \n4911        5618                                         Fenner USA   \n1986        2758                 Fms Logistics Mexico S De Rl De Cv   \n5298        6067  Bridgestone India Automotive Products Private ...   \n4333        4955                                         K Flex Usa   \n3296        3774                         Brenntag Vietnam Co., Ltd.   \n4772        5458         Sumitomo Industrias Pesadas Do Brasil Ltda   \n909         1497            Commerce Logistics (Shanghai) Co., Ltd.   \n4549        5202                     Bridgestone De Costa Rica S.A.   \n4942        5650                        Bridgestone Stargard Sp Zoo   \n1992         305                          Promaflex Industrial Ltda   \n1173        1823                 Firekiller Engineering And Service   \n1177        1827             Shahbaz Chemical Industries Pvt., Ltd.   \n4728        5409                 Bridgestone Firestone Venezolana C   \n\n                                                 name_2  is_duplicate  \n4798                           РУСПЛАСТ, ООО (ЛОБАНОВО)             1  \n1264  Ningbo Green Was Imp. & Exp. . Co., Ltd. Was C...             0  \n4911                             Fenner Precision, Inc.             1  \n1986                                               Epic             0  \n5298                                  Bridgestone India             1  \n4333                                 Planika Flex D.O.O             1  \n3296                          Brenntag Ingredients Inc.             1  \n4772                     Sumitomo Rubber Industries Usa             1  \n909                         Bi Link(Shanghai) Co., Ltd.             0  \n4549                 Bridgestone De Mexico S.A. De C.V.             1  \n4942    Bridgestone Do Brasil Industria E Comercio Ltda             1  \n1992                   Cube Industrial Corporation Ltd.             0  \n1173                                                Dsi             0  \n1177                             Clifex Industries Ltd.             0  \n4728           Bridgestone Firestone De Mexico Sa De Cv             1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>name_1</th>\n      <th>name_2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4798</th>\n      <td>5488</td>\n      <td>ООО Руспласт</td>\n      <td>РУСПЛАСТ, ООО (ЛОБАНОВО)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1264</th>\n      <td>688</td>\n      <td>Dawn Imp. &amp; Exp.</td>\n      <td>Ningbo Green Was Imp. &amp; Exp. . Co., Ltd. Was C...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4911</th>\n      <td>5618</td>\n      <td>Fenner USA</td>\n      <td>Fenner Precision, Inc.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1986</th>\n      <td>2758</td>\n      <td>Fms Logistics Mexico S De Rl De Cv</td>\n      <td>Epic</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5298</th>\n      <td>6067</td>\n      <td>Bridgestone India Automotive Products Private ...</td>\n      <td>Bridgestone India</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4333</th>\n      <td>4955</td>\n      <td>K Flex Usa</td>\n      <td>Planika Flex D.O.O</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3296</th>\n      <td>3774</td>\n      <td>Brenntag Vietnam Co., Ltd.</td>\n      <td>Brenntag Ingredients Inc.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4772</th>\n      <td>5458</td>\n      <td>Sumitomo Industrias Pesadas Do Brasil Ltda</td>\n      <td>Sumitomo Rubber Industries Usa</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>909</th>\n      <td>1497</td>\n      <td>Commerce Logistics (Shanghai) Co., Ltd.</td>\n      <td>Bi Link(Shanghai) Co., Ltd.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4549</th>\n      <td>5202</td>\n      <td>Bridgestone De Costa Rica S.A.</td>\n      <td>Bridgestone De Mexico S.A. De C.V.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4942</th>\n      <td>5650</td>\n      <td>Bridgestone Stargard Sp Zoo</td>\n      <td>Bridgestone Do Brasil Industria E Comercio Ltda</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1992</th>\n      <td>305</td>\n      <td>Promaflex Industrial Ltda</td>\n      <td>Cube Industrial Corporation Ltd.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1173</th>\n      <td>1823</td>\n      <td>Firekiller Engineering And Service</td>\n      <td>Dsi</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1177</th>\n      <td>1827</td>\n      <td>Shahbaz Chemical Industries Pvt., Ltd.</td>\n      <td>Clifex Industries Ltd.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4728</th>\n      <td>5409</td>\n      <td>Bridgestone Firestone Venezolana C</td>\n      <td>Bridgestone Firestone De Mexico Sa De Cv</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def seed_everything(seed = 1234):\n     random.seed(seed)\n     os.environ['PYTHONHASHSEED'] = str(seed)\n     np.random.seed(seed)     \n     torch.manual_seed(seed)\n     torch.cuda.manual_seed(seed)\n     torch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2022-10-13T14:39:07.562009Z","iopub.execute_input":"2022-10-13T14:39:07.562412Z","iopub.status.idle":"2022-10-13T14:39:07.568896Z","shell.execute_reply.started":"2022-10-13T14:39:07.562378Z","shell.execute_reply":"2022-10-13T14:39:07.567752Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"seed_everything()","metadata":{"execution":{"iopub.status.busy":"2022-10-13T14:39:09.519618Z","iopub.execute_input":"2022-10-13T14:39:09.520030Z","iopub.status.idle":"2022-10-13T14:39:09.528292Z","shell.execute_reply.started":"2022-10-13T14:39:09.519998Z","shell.execute_reply":"2022-10-13T14:39:09.527289Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"raw_model = 'bert-base-uncased'\ntokenizer = BertTokenizerFast.from_pretrained(raw_model, do_lower_case=True)\nmodel = BertForSequenceClassification.from_pretrained(\n    raw_model, \n    num_labels=2, \n    output_attentions=False,\n    output_hidden_states=True, \n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_to_dataset_torch(data: pd.DataFrame, labels: pd.Series) -> TensorDataset:\n    input_ids = []\n    attention_masks = []\n    token_type_ids = []\n    for _, row in tqdm(data.iterrows(), total=data.shape[0]):\n        encoded_dict = tokenizer.encode_plus(row[\"name_1\"], row[\"name_2\"], max_length=300,\n                                             pad_to_max_length=True,\n                                             return_attention_mask=True, return_tensors='pt', truncation=True)\n        # Add the encoded sentences to the list.\n        input_ids.append(encoded_dict['input_ids'])\n        token_type_ids.append(encoded_dict[\"token_type_ids\"])\n        # And its attention mask (simply differentiates padding from non-padding).\n        attention_masks.append(encoded_dict['attention_mask'])\n\n    # Convert the lists into tensors.\n\n    input_ids = torch.cat(input_ids, dim=0)\n    token_type_ids = torch.cat(token_type_ids, dim=0)\n    attention_masks = torch.cat(attention_masks, dim=0)\n    labels = torch.tensor(labels.values)\n    input_ids.to(dtype=torch.long)\n    token_type_ids.to(dtype=torch.long)\n    attention_masks.to(dtype=torch.long)\n    labels.to(dtype=torch.long)\n\n    return TensorDataset(input_ids, attention_masks, token_type_ids, labels)","metadata":{"execution":{"iopub.status.busy":"2022-10-13T14:40:07.741870Z","iopub.execute_input":"2022-10-13T14:40:07.742517Z","iopub.status.idle":"2022-10-13T14:40:07.763887Z","shell.execute_reply.started":"2022-10-13T14:40:07.742469Z","shell.execute_reply":"2022-10-13T14:40:07.762498Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X_train, X_validation, y_train, y_validation = train_test_split(df[[\"name_1\", \"name_2\"]],\n                                                    df[\"is_duplicate\"], test_size=0.3, random_state=42, stratify=df[\"is_duplicate\"])","metadata":{"execution":{"iopub.status.busy":"2022-10-13T14:40:11.131177Z","iopub.execute_input":"2022-10-13T14:40:11.131765Z","iopub.status.idle":"2022-10-13T14:40:11.149942Z","shell.execute_reply.started":"2022-10-13T14:40:11.131718Z","shell.execute_reply":"2022-10-13T14:40:11.149027Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train = convert_to_dataset_torch(X_train, y_train)\nvalidation = convert_to_dataset_torch(X_validation, y_validation)","metadata":{"execution":{"iopub.status.busy":"2022-10-13T14:40:13.784435Z","iopub.execute_input":"2022-10-13T14:40:13.784892Z","iopub.status.idle":"2022-10-13T14:40:17.966558Z","shell.execute_reply.started":"2022-10-13T14:40:13.784851Z","shell.execute_reply":"2022-10-13T14:40:17.965446Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"  0%|          | 0/4475 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\n100%|██████████| 4475/4475 [00:02<00:00, 1637.58it/s]\n100%|██████████| 1919/1919 [00:01<00:00, 1414.18it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 8","metadata":{"execution":{"iopub.status.busy":"2022-10-13T14:40:20.268953Z","iopub.execute_input":"2022-10-13T14:40:20.269339Z","iopub.status.idle":"2022-10-13T14:40:20.274140Z","shell.execute_reply.started":"2022-10-13T14:40:20.269304Z","shell.execute_reply":"2022-10-13T14:40:20.272823Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(\n            train,  \n            sampler = RandomSampler(train),\n            batch_size = batch_size,\n            num_workers = 0,\n            drop_last=True\n        )\n\n\nvalidation_dataloader = DataLoader(\n            validation, \n            sampler = SequentialSampler(validation), \n            batch_size = batch_size, \n            num_workers = 0,\n            drop_last=True\n        )","metadata":{"execution":{"iopub.status.busy":"2022-10-13T14:40:22.926355Z","iopub.execute_input":"2022-10-13T14:40:22.927058Z","iopub.status.idle":"2022-10-13T14:40:22.933189Z","shell.execute_reply.started":"2022-10-13T14:40:22.927021Z","shell.execute_reply":"2022-10-13T14:40:22.931988Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)","metadata":{"execution":{"iopub.status.busy":"2022-10-13T14:40:26.675638Z","iopub.execute_input":"2022-10-13T14:40:26.676204Z","iopub.status.idle":"2022-10-13T14:40:26.690377Z","shell.execute_reply.started":"2022-10-13T14:40:26.676160Z","shell.execute_reply":"2022-10-13T14:40:26.689461Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n","output_type":"stream"}]},{"cell_type":"code","source":"epochs = 7\ntotal_steps = len(train_dataloader) * epochs","metadata":{"execution":{"iopub.status.busy":"2022-10-13T14:40:29.142266Z","iopub.execute_input":"2022-10-13T14:40:29.142818Z","iopub.status.idle":"2022-10-13T14:40:29.152918Z","shell.execute_reply.started":"2022-10-13T14:40:29.142773Z","shell.execute_reply":"2022-10-13T14:40:29.151522Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"scheduler = get_linear_schedule_with_warmup(optimizer,\n                                            num_warmup_steps = 0,\n                                            num_training_steps = total_steps)","metadata":{"execution":{"iopub.status.busy":"2022-10-13T14:40:32.197150Z","iopub.execute_input":"2022-10-13T14:40:32.197673Z","iopub.status.idle":"2022-10-13T14:40:32.206218Z","shell.execute_reply.started":"2022-10-13T14:40:32.197637Z","shell.execute_reply":"2022-10-13T14:40:32.204893Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"DEVICE = 'cuda:0'","metadata":{"execution":{"iopub.status.busy":"2022-10-13T14:40:34.885223Z","iopub.execute_input":"2022-10-13T14:40:34.885863Z","iopub.status.idle":"2022-10-13T14:40:34.890934Z","shell.execute_reply.started":"2022-10-13T14:40:34.885827Z","shell.execute_reply":"2022-10-13T14:40:34.889649Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model.to(DEVICE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit_batch(dataloader, model, optimizer, epoch):\n    total_train_loss = 0\n\n    for batch in tqdm(dataloader, desc=f\"Training epoch:{epoch}\", unit=\"batch\"):\n      \n        input_ids, attention_masks, token_type_ids, labels = batch\n\n        \n        input_ids = input_ids.to(DEVICE)\n        token_type_ids = token_type_ids.to(DEVICE)\n        attention_masks = attention_masks.to(DEVICE)\n        #labels = labels.long()\n        labels = labels.to(DEVICE)\n\n        loss = (model(input_ids=input_ids,\n                      token_type_ids=token_type_ids,\n                      attention_mask=attention_masks,\n                      labels=labels)).loss\n\n        total_train_loss += loss\n        optimizer.zero_grad()\n\n        loss.backward()\n\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n        optimizer.step()\n\n        scheduler.step()\n\n    return total_train_loss","metadata":{"execution":{"iopub.status.busy":"2022-10-13T14:40:54.157875Z","iopub.execute_input":"2022-10-13T14:40:54.158271Z","iopub.status.idle":"2022-10-13T14:40:54.166093Z","shell.execute_reply.started":"2022-10-13T14:40:54.158219Z","shell.execute_reply":"2022-10-13T14:40:54.165071Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def eval_batch(dataloader, model, metric=accuracy_score):\n    total_eval_accuracy = 0\n    total_eval_loss = 0\n    predictions, predicted_labels = [], []\n    notright = []\n    for batch in tqdm(dataloader, desc=\"Evaluating\", unit=\"batch\"):\n   \n        input_ids, attention_masks, token_type_ids, labels = batch\n\n        input_ids = input_ids.to(DEVICE)\n        token_type_ids = token_type_ids.to(DEVICE)\n        attention_masks = attention_masks.to(DEVICE)\n        labels = labels.to(DEVICE)\n        with torch.no_grad():\n           \n            m = (model(input_ids,\n                       token_type_ids=token_type_ids,\n                       attention_mask=attention_masks,\n                       labels=labels))\n        total_eval_loss += m.loss\n\n        y_pred = np.argmax(m.logits.detach().cpu().numpy(), axis=1).flatten()\n        total_eval_accuracy += metric(labels.cpu(), y_pred)\n\n        predictions.extend(m.logits.detach().tolist())\n        predicted_labels.extend(y_pred.tolist())\n        if y_pred !=labels:\n            notright.append((input_ids, token_type_ids, attention_masks, labels, y_pred))\n    return total_eval_accuracy, total_eval_loss, predictions, predicted_labels, notright\n","metadata":{"execution":{"iopub.status.busy":"2022-10-13T15:05:46.149133Z","iopub.execute_input":"2022-10-13T15:05:46.149860Z","iopub.status.idle":"2022-10-13T15:05:46.159775Z","shell.execute_reply.started":"2022-10-13T15:05:46.149823Z","shell.execute_reply":"2022-10-13T15:05:46.158391Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"def train(train_dataloader, validation_dataloader, model, optimizer, epochs):\n\n    training_stats = []\n\n\n\n    for epoch in range(0, epochs):\n\n        \n        total_train_loss = 0\n\n        model.train()\n\n        total_train_loss = fit_batch(train_dataloader, model, optimizer, epoch)\n\n        avg_train_loss = total_train_loss / len(train_dataloader)\n        print(f\"  Train Loss: {avg_train_loss}\")\n   \n        model.eval()\n\n        total_eval_accuracy, total_eval_loss, _, _ = eval_batch(validation_dataloader, model)\n        FILE = 'modelnew.pth'\n        torch.save(model, FILE)\n       \n        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n\n        print(f\"  Accuracy: {avg_val_accuracy}\")\n\n      \n        avg_val_loss = total_eval_loss / len(validation_dataloader)\n\n\n        print(f\"  Validation Loss: {avg_val_loss}\")\n\n     \n        training_stats.append(\n            {\n                'epoch': epoch,\n                'Training Loss': avg_train_loss,\n                'Valid. Loss': avg_val_loss,\n                'Valid. Accur.': avg_val_accuracy,\n            }\n        )\n\n    print(\"\")\n    print(\"Training complete!\")\n    return training_stats","metadata":{"execution":{"iopub.status.busy":"2022-10-13T14:41:00.301367Z","iopub.execute_input":"2022-10-13T14:41:00.302399Z","iopub.status.idle":"2022-10-13T14:41:00.313587Z","shell.execute_reply.started":"2022-10-13T14:41:00.302348Z","shell.execute_reply":"2022-10-13T14:41:00.312585Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"training_stats = train(train_dataloader, validation_dataloader, model, optimizer, epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_eval_accuracy, total_eval_loss, preds, predslab, notr = eval_batch(validation_dataloader, model)","metadata":{"execution":{"iopub.status.busy":"2022-10-13T15:05:49.727613Z","iopub.execute_input":"2022-10-13T15:05:49.727981Z","iopub.status.idle":"2022-10-13T15:06:12.714841Z","shell.execute_reply.started":"2022-10-13T15:05:49.727950Z","shell.execute_reply":"2022-10-13T15:06:12.712561Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 239/239 [00:22<00:00, 10.40batch/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"len(notr)","metadata":{"execution":{"iopub.status.busy":"2022-10-13T15:06:36.578844Z","iopub.execute_input":"2022-10-13T15:06:36.579225Z","iopub.status.idle":"2022-10-13T15:06:36.589198Z","shell.execute_reply.started":"2022-10-13T15:06:36.579191Z","shell.execute_reply":"2022-10-13T15:06:36.588034Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"239"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}