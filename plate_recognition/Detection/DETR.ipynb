{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers timm","metadata":{"execution":{"iopub.status.busy":"2022-10-04T08:00:18.986525Z","iopub.execute_input":"2022-10-04T08:00:18.986966Z","iopub.status.idle":"2022-10-04T08:00:34.116677Z","shell.execute_reply.started":"2022-10-04T08:00:18.986879Z","shell.execute_reply":"2022-10-04T08:00:34.115084Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import torchvision\nimport os\nimport numpy as np\nfrom PIL import Image, ImageDraw\nfrom torch.utils.data import DataLoader\nfrom transformers import DetrFeatureExtractor, DetrForObjectDetection\nimport torch.nn as nn\nimport torch","metadata":{"execution":{"iopub.status.busy":"2022-10-04T08:00:38.019776Z","iopub.execute_input":"2022-10-04T08:00:38.020282Z","iopub.status.idle":"2022-10-04T08:00:41.123665Z","shell.execute_reply.started":"2022-10-04T08:00:38.020231Z","shell.execute_reply":"2022-10-04T08:00:41.122532Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class CocoDetection(torchvision.datasets.CocoDetection):\n    def __init__(self, img_folder, feature_extractor, train=True):\n        ann_file = os.path.join(img_folder, \"custom_train.json\" if train else \"custom_val.json\")\n        super(CocoDetection, self).__init__(img_folder, ann_file)\n        self.feature_extractor = feature_extractor\n\n    def __getitem__(self, idx):\n        # read in PIL image and target in COCO format\n        img, target = super(CocoDetection, self).__getitem__(idx)\n        \n        # preprocess image and target (converting target to DETR format, resizing + normalization of both image and target)\n        image_id = self.ids[idx]\n        target = {'image_id': image_id, 'annotations': target}\n        encoding = self.feature_extractor(images=img, annotations=target, return_tensors=\"pt\")\n        pixel_values = encoding[\"pixel_values\"].squeeze() # remove batch dimension\n        target = encoding[\"labels\"][0] # remove batch dimension\n\n        return pixel_values, target","metadata":{"execution":{"iopub.status.busy":"2022-10-04T08:01:11.789361Z","iopub.execute_input":"2022-10-04T08:01:11.790411Z","iopub.status.idle":"2022-10-04T08:01:11.799798Z","shell.execute_reply.started":"2022-10-04T08:01:11.790371Z","shell.execute_reply":"2022-10-04T08:01:11.797760Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install pycocotools","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_extractor = DetrFeatureExtractor.from_pretrained(\"facebook/detr-resnet-50\")\ntrain_dataset = CocoDetection(img_folder='../input/licenseplates2/train', feature_extractor=feature_extractor)\nval_dataset = CocoDetection(img_folder='../input/licenseplates2/valid', feature_extractor=feature_extractor, train=False)","metadata":{"execution":{"iopub.status.busy":"2022-10-04T08:01:58.022472Z","iopub.execute_input":"2022-10-04T08:01:58.023690Z","iopub.status.idle":"2022-10-04T08:01:58.781520Z","shell.execute_reply.started":"2022-10-04T08:01:58.023644Z","shell.execute_reply":"2022-10-04T08:01:58.780458Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/274 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e90609f6fe54b82be8f4a6126517645"}},"metadata":{}},{"name":"stdout","text":"loading annotations into memory...\nDone (t=0.01s)\ncreating index...\nindex created!\nloading annotations into memory...\nDone (t=0.01s)\ncreating index...\nindex created!\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef collate_fn(batch):\n  pixel_values = [item[0] for item in batch]\n  encoding = feature_extractor.pad_and_create_pixel_mask(pixel_values, return_tensors=\"pt\")\n  labels = [item[1] for item in batch]\n  batch = {}\n  batch['pixel_values'] = encoding['pixel_values']\n  batch['pixel_mask'] = encoding['pixel_mask']\n  batch['labels'] = labels\n  return batch\n\ntrain_dataloader = DataLoader(train_dataset, collate_fn=collate_fn, batch_size=8, shuffle=True)\nval_dataloader = DataLoader(val_dataset, collate_fn=collate_fn, batch_size=2)\nbatch = next(iter(train_dataloader))","metadata":{"execution":{"iopub.status.busy":"2022-10-04T08:02:03.554261Z","iopub.execute_input":"2022-10-04T08:02:03.554722Z","iopub.status.idle":"2022-10-04T08:02:04.574219Z","shell.execute_reply.started":"2022-10-04T08:02:03.554659Z","shell.execute_reply":"2022-10-04T08:02:04.560870Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"device = 'cuda:0'","metadata":{"execution":{"iopub.status.busy":"2022-10-04T08:02:06.506364Z","iopub.execute_input":"2022-10-04T08:02:06.506726Z","iopub.status.idle":"2022-10-04T08:02:06.511708Z","shell.execute_reply.started":"2022-10-04T08:02:06.506696Z","shell.execute_reply":"2022-10-04T08:02:06.510707Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\", \n                                                             ignore_mismatched_sizes=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3,\n                                  weight_decay=1e-4)","metadata":{"execution":{"iopub.status.busy":"2022-10-04T08:02:34.387641Z","iopub.execute_input":"2022-10-04T08:02:34.388348Z","iopub.status.idle":"2022-10-04T08:02:34.396188Z","shell.execute_reply.started":"2022-10-04T08:02:34.388312Z","shell.execute_reply":"2022-10-04T08:02:34.394294Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 50","metadata":{"execution":{"iopub.status.busy":"2022-10-04T08:02:44.433178Z","iopub.execute_input":"2022-10-04T08:02:44.433533Z","iopub.status.idle":"2022-10-04T08:02:44.437814Z","shell.execute_reply.started":"2022-10-04T08:02:44.433503Z","shell.execute_reply":"2022-10-04T08:02:44.436870Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def mean(numb: list):\n    return sum(numb)/len(numb)","metadata":{"execution":{"iopub.status.busy":"2022-10-04T08:02:48.362619Z","iopub.execute_input":"2022-10-04T08:02:48.362995Z","iopub.status.idle":"2022-10-04T08:02:48.369641Z","shell.execute_reply.started":"2022-10-04T08:02:48.362964Z","shell.execute_reply":"2022-10-04T08:02:48.366545Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from transformers import get_linear_schedule_with_warmup\ntotal_steps = len(train_dataloader) * epochs\nscheduler = get_linear_schedule_with_warmup(optimizer,\n                                            num_warmup_steps=0, num_training_steps=total_steps)","metadata":{"execution":{"iopub.status.busy":"2022-10-04T08:02:51.025851Z","iopub.execute_input":"2022-10-04T08:02:51.026545Z","iopub.status.idle":"2022-10-04T08:02:54.856932Z","shell.execute_reply.started":"2022-10-04T08:02:51.026509Z","shell.execute_reply":"2022-10-04T08:02:54.855941Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"meanloss = []\nfor epoch in range(epochs):\n \n losses = []\n print('epoch: '+ str(epoch))\n for batch in train_dataloader:\n    pixel_values = batch[\"pixel_values\"]\n    pixel_mask = batch[\"pixel_mask\"]\n    labels = [{k: v.to(device) for k, v in t.items()} for t in batch[\"labels\"]]\n    pixel_values = pixel_values.to(device)\n    pixel_mask = pixel_mask.to(device)\n    outputs = model(pixel_values=pixel_values, pixel_mask=pixel_mask, labels=labels)\n    loss = outputs.loss\n    \n\n    optimizer.zero_grad()\n\n\n    loss.backward()\n\n    optimizer.step()\n    scheduler.step()\n    losses.append(loss)\n print('mean loss: ' + str(mean(losses)))\n meanloss.append(mean(losses))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model, 'DETR50eps.pth')","metadata":{"execution":{"iopub.status.busy":"2022-10-04T07:37:29.682410Z","iopub.status.idle":"2022-10-04T07:37:29.683196Z","shell.execute_reply.started":"2022-10-04T07:37:29.682932Z","shell.execute_reply":"2022-10-04T07:37:29.682968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport matplotlib.pyplot as plt\n\n# colors for visualization\nCOLORS = [[0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n          [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]]\n\n# for output bounding box post-processing\ndef box_cxcywh_to_xyxy(x):\n    x_c, y_c, w, h = x.unbind(1)\n    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n    return torch.stack(b, dim=1)\n\ndef rescale_bboxes(out_bbox, size):\n    img_w, img_h = size\n    b = box_cxcywh_to_xyxy(out_bbox)\n    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)\n    return b\n\ndef plot_results(pil_img, prob, boxes):\n    plt.figure(figsize=(16,10))\n    plt.imshow(pil_img)\n    ax = plt.gca()\n    colors = COLORS * 100\n    for p, (xmin, ymin, xmax, ymax), c in zip(prob, boxes.tolist(), colors):\n        ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n                                   fill=False, color=c, linewidth=3))\n        cl = p.argmax()\n        #text = f'{id2label[cl.item()]}: {p[cl]:0.2f}'\n        ax.text(xmin, ymin, text, fontsize=15,\n                bbox=dict(facecolor='yellow', alpha=0.5))\n    plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-10-04T07:37:29.684625Z","iopub.status.idle":"2022-10-04T07:37:29.685437Z","shell.execute_reply.started":"2022-10-04T07:37:29.685155Z","shell.execute_reply":"2022-10-04T07:37:29.685179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_predictions(image, outputs, threshold=0.9, keep_highest_scoring_bbox=False):\n  # keep only predictions with confidence >= threshold\n  probas = outputs.logits.softmax(-1)[0, :, :-1]\n  keep = probas.max(-1).values > threshold\n  if keep_highest_scoring_bbox:\n    keep = probas.max(-1).values.argmax()\n    keep = torch.tensor([keep])\n  \n  # convert predicted boxes from [0; 1] to image scales\n  bboxes_scaled = rescale_bboxes(outputs.pred_boxes[0, keep].cpu(), image.size)\n    \n  # plot results\n  plot_results(image, probas[keep], bboxes_scaled)","metadata":{"execution":{"iopub.status.busy":"2022-10-04T07:37:29.686869Z","iopub.status.idle":"2022-10-04T07:37:29.687667Z","shell.execute_reply.started":"2022-10-04T07:37:29.687403Z","shell.execute_reply":"2022-10-04T07:37:29.687427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"it = iter(range(1500))","metadata":{"execution":{"iopub.status.busy":"2022-10-04T07:37:29.689084Z","iopub.status.idle":"2022-10-04T07:37:29.689888Z","shell.execute_reply.started":"2022-10-04T07:37:29.689630Z","shell.execute_reply":"2022-10-04T07:37:29.689656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pixel_values, target = val_dataset[next(it)]\n\npixel_values = pixel_values.unsqueeze(0).to(device)\nprint(pixel_values.shape)\n\n# forward pass to get class logits and bounding boxes\noutputs = model(pixel_values=pixel_values, pixel_mask=None)\n\nimage_id = target['image_id'].item()\nimage = val_dataset.coco.loadImgs(image_id)[0]\nimage = Image.open(os.path.join('../input/licenseplates2/valid', image['file_name']))\n\nvisualize_predictions(image, outputs, threshold=0.3, keep_highest_scoring_bbox=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-04T07:37:29.691460Z","iopub.status.idle":"2022-10-04T07:37:29.692264Z","shell.execute_reply.started":"2022-10-04T07:37:29.691986Z","shell.execute_reply":"2022-10-04T07:37:29.692011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}